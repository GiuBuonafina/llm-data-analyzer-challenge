# LLM Data Analyzer Challenge ğŸ¤–

Este projeto foi desenvolvido como parte do processo seletivo da **Neurotech**.  
Seu objetivo Ã© demonstrar a construÃ§Ã£o de um sistema de anÃ¡lise de dados conversacional, onde o usuÃ¡rio pode interagir via terminal em linguagem natural e obter respostas baseadas em consultas SQL geradas automaticamente por uma LLM (Large Language Model).

---

## PropÃ³sito

Permitir que qualquer pessoa, mesmo sem conhecimento tÃ©cnico em SQL, possa consultar e analisar dados de um banco relacional apenas conversando em linguagem natural.  
O sistema interpreta a intenÃ§Ã£o do usuÃ¡rio, gera a consulta SQL adequada, executa no banco e retorna a resposta de forma clara e amigÃ¡vel.

---

## OrganizaÃ§Ã£o do Projeto

A estrutura foi pensada para **extensibilidade**, **clareza** e **facilidade de manutenÃ§Ã£o**:

```
llm-data-analyzer-challenge/
â”‚
â”œâ”€â”€ main.py                  # Ponto de entrada do sistema (interface terminal, atÃ© o momento)
â”œâ”€â”€ config.py                # Carregamento de variÃ¡veis de ambiente
â”œâ”€â”€ requirements.txt         # DependÃªncias do projeto
â”‚
â”œâ”€â”€ core/                    # LÃ³gica principal desacoplada
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ db_utils.py          # FunÃ§Ãµes para interaÃ§Ã£o com banco de dados
â”‚   â”œâ”€â”€ llm_utils.py         # FunÃ§Ãµes para interaÃ§Ã£o com LLM (OpenAI/Azure)
â”‚   â””â”€â”€ prompt_utils.py      # UtilitÃ¡rios para prompts e leitura de recursos
â”‚
â”œâ”€â”€ resources/               # Arquivos de apoio facilmente editÃ¡veis
â”‚   â”œâ”€â”€ sintax.txt           # Regras de sintaxe SQL (desacoplado do cÃ³digo)
â”‚   â””â”€â”€ data_dictionary.txt  # DicionÃ¡rio de dados (desacoplado do cÃ³digo)
â”‚
â”œâ”€â”€ tests/                   # Testes unitÃ¡rios com pytest
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_db_utils.py
â”‚   â””â”€â”€ test_llm_utils.py
â”‚
â””â”€â”€ __init__.py
```

**Principais escolhas de design:**
- **ModularizaÃ§Ã£o:** Cada responsabilidade em um arquivo/mÃ³dulo.
- **Recursos desacoplados:** Sintaxe SQL e dicionÃ¡rio de dados ficam em arquivos `.txt` na pasta `resources/`, facilitando manutenÃ§Ã£o e extensÃ£o para outros bancos ou domÃ­nios.
- **Testabilidade:** Testes unitÃ¡rios para funÃ§Ãµes crÃ­ticas, garantindo robustez.
- **HistÃ³rico de conversa:** Todo o histÃ³rico Ã© mantido e passado para as funÃ§Ãµes de LLM, permitindo contexto conversacional.

---

## ğŸ—„ï¸ Base de Dados

A base de dados utilizada neste projeto pode ser encontrada em:  
[https://github.com/Neurolake/challenge-data-scientist/blob/main/datasets/credit_01/train.gz](https://github.com/Neurolake/challenge-data-scientist/blob/main/datasets/credit_01/train.gz)

---

## ğŸ–¥ï¸ Como executar localmente

### 1. Clone o repositÃ³rio

```sh
git clone https://github.com/GiuBuonafina/llm-data-analyzer-challenge.git
cd llm-data-analyzer-challenge
```

### 2. Crie e ative um ambiente virtual

```sh
python -m venv venv
# No Windows:
venv\Scripts\activate
# No Linux/Mac:
source venv/bin/activate
```

### 3. Instale as dependÃªncias

```sh
pip install -r requirements.txt
```

### 4. Configure as variÃ¡veis de ambiente

Copie o arquivo `Configuration.env.example` para `Configuration.env` e preencha com seus dados de conexÃ£o e credenciais antes de rodar o projeto.  


### 5. Execute o sistema

```sh
python main.py
```

VocÃª verÃ¡ o prompt do assistente no terminal. Basta digitar suas perguntas!

---

## Rodando os testes

```sh
pytest
```

---


**Desenvolvido como parte do processo seletivo da Neurotech.**